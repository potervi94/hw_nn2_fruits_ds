{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vpotereyko/hw-nn2-fruits-ds?scriptVersionId=298336881\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\n\n# Подивимось на структуру папок датасету\ndata_path = \"/kaggle/input\"\n\nfor dirname, _, filenames in os.walk(data_path):\n    # Показуємо тільки назви папок (класи), не всі файли\n    level = dirname.replace(data_path, '').count(os.sep)\n    indent = ' ' * 2 * level\n    print(f'{indent}{os.path.basename(dirname)}/')\n    if level >= 2:  # не заглиблюємось далі 2 рівнів\n        continue","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:34:14.366081Z","iopub.execute_input":"2026-02-18T03:34:14.366437Z","iopub.status.idle":"2026-02-18T03:34:36.593152Z","shell.execute_reply.started":"2026-02-18T03:34:14.366409Z","shell.execute_reply":"2026-02-18T03:34:36.591528Z"}},"outputs":[{"name":"stdout","text":"input/\n  datasets/\n    sshikamaru/\n      fruit-recognition/\n        test/\n          test/\n        train/\n          train/\n            Orange/\n            Tomato/\n            Passion Fruit/\n            Cucumber Ripe/\n            Cactus fruit/\n            Pomegranate/\n            Plum/\n            Pineapple/\n            Papaya/\n            Potato Red/\n            Kiwi/\n            Limes/\n            Apple Braeburn/\n            Pear/\n            Onion White/\n            Strawberry/\n            Grape Blue/\n            Blueberry/\n            Apple Granny Smith/\n            Apricot/\n            Pepper Red/\n            Clementine/\n            Lemon/\n            Avocado/\n            Raspberry/\n            Cantaloupe/\n            Peach/\n            Corn/\n            Banana/\n            Cherry/\n            Pepper Green/\n            Watermelon/\n            Mango/\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:37:11.382933Z","iopub.execute_input":"2026-02-18T03:37:11.383279Z","iopub.status.idle":"2026-02-18T03:37:21.46991Z","shell.execute_reply.started":"2026-02-18T03:37:11.383253Z","shell.execute_reply":"2026-02-18T03:37:21.46868Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Трансформації для тренувальних даних (з аугментацією)\n# Посилання: https://pytorch.org/vision/stable/transforms.html\n# Навіщо це потрібно: нейромережа вчиться краще, коли бачить більше різноманітних прикладів.\n# Без аугментації вона може \"завчити\" конкретні фото замість того,\n# щоб зрозуміти загальні ознаки фрукта.\n# Аугментація — це коли ти штучно \"розмножуєш\" свої фотографії, трохи змінюючи кожну.\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),           # Змінюємо розмір до 224x224\n    transforms.RandomHorizontalFlip(p=0.5),  # Випадковий горизонтальний переворот\n    transforms.RandomRotation(10),           # Випадковий поворот до 10 градусів\n    transforms.ToTensor(),                   # Конвертуємо в тензор [0, 1]\n])\n\n# Трансформації для тестових даних (без аугментації)\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),           # Тільки змінюємо розмір\n    transforms.ToTensor(),                   # Конвертуємо в тензор\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:42:49.65752Z","iopub.execute_input":"2026-02-18T03:42:49.65791Z","iopub.status.idle":"2026-02-18T03:42:49.664243Z","shell.execute_reply.started":"2026-02-18T03:42:49.657878Z","shell.execute_reply":"2026-02-18T03:42:49.66326Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Шлях до даних \n# Cтруктура у Блоку 1\ntrain_path = \"/kaggle/input/datasets/sshikamaru/fruit-recognition/train/train\"\ntest_path = \"/kaggle/input/datasets/sshikamaru/fruit-recognition/test\"\n\n# Створюємо датасети з відповідними трансформаціями\ntrain_dataset = datasets.ImageFolder(train_path, transform=train_transform)\ntest_dataset = datasets.ImageFolder(test_path, transform=test_transform)\n\nprint(f\"Кількість тренувальних зразків: {len(train_dataset)}\")\nprint(f\"Кількість тестових зразків: {len(test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:50:13.646151Z","iopub.execute_input":"2026-02-18T03:50:13.646495Z","iopub.status.idle":"2026-02-18T03:50:34.384658Z","shell.execute_reply.started":"2026-02-18T03:50:13.646467Z","shell.execute_reply":"2026-02-18T03:50:34.38325Z"}},"outputs":[{"name":"stdout","text":"Кількість тренувальних зразків: 16854\nКількість тестових зразків: 5641\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Назви класів (фруктів)\nprint(f\"Кількість класів: {len(train_dataset.classes)}\")\nprint(f\"Класи: {train_dataset.classes}\")\nprint(f\"\\nclass_to_idx: {train_dataset.class_to_idx}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:53:01.621931Z","iopub.execute_input":"2026-02-18T03:53:01.622911Z","iopub.status.idle":"2026-02-18T03:53:01.628342Z","shell.execute_reply.started":"2026-02-18T03:53:01.622873Z","shell.execute_reply":"2026-02-18T03:53:01.627187Z"}},"outputs":[{"name":"stdout","text":"Кількість класів: 33\nКласи: ['Apple Braeburn', 'Apple Granny Smith', 'Apricot', 'Avocado', 'Banana', 'Blueberry', 'Cactus fruit', 'Cantaloupe', 'Cherry', 'Clementine', 'Corn', 'Cucumber Ripe', 'Grape Blue', 'Kiwi', 'Lemon', 'Limes', 'Mango', 'Onion White', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Pear', 'Pepper Green', 'Pepper Red', 'Pineapple', 'Plum', 'Pomegranate', 'Potato Red', 'Raspberry', 'Strawberry', 'Tomato', 'Watermelon']\n\nclass_to_idx: {'Apple Braeburn': 0, 'Apple Granny Smith': 1, 'Apricot': 2, 'Avocado': 3, 'Banana': 4, 'Blueberry': 5, 'Cactus fruit': 6, 'Cantaloupe': 7, 'Cherry': 8, 'Clementine': 9, 'Corn': 10, 'Cucumber Ripe': 11, 'Grape Blue': 12, 'Kiwi': 13, 'Lemon': 14, 'Limes': 15, 'Mango': 16, 'Onion White': 17, 'Orange': 18, 'Papaya': 19, 'Passion Fruit': 20, 'Peach': 21, 'Pear': 22, 'Pepper Green': 23, 'Pepper Red': 24, 'Pineapple': 25, 'Plum': 26, 'Pomegranate': 27, 'Potato Red': 28, 'Raspberry': 29, 'Strawberry': 30, 'Tomato': 31, 'Watermelon': 32}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Подивимось на перший зразок\nimg, label = train_dataset[0]\nprint(f\"Тип: {type(img)}\")\nprint(f\"Форма тензора: {img.shape}\")  # [C, H, W] = [3, 224, 224]\nprint(f\"Мітка (індекс): {label}\")\nprint(f\"Назва класу: {train_dataset.classes[label]}\")\n\n# Перший зразок з кожного класу (до 5 класів)\nshown_classes = set()\nfor i in range(len(train_dataset)):\n    img, label = train_dataset[i]\n    if label not in shown_classes:\n        print(f\"Зразок [{i}]: форма {img.shape}, мітка: {label} → {train_dataset.classes[label]}\")\n        shown_classes.add(label)\n    if len(shown_classes) >= 5:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T03:58:32.181919Z","iopub.execute_input":"2026-02-18T03:58:32.182424Z","iopub.status.idle":"2026-02-18T03:58:41.23671Z","shell.execute_reply.started":"2026-02-18T03:58:32.182391Z","shell.execute_reply":"2026-02-18T03:58:41.235861Z"}},"outputs":[{"name":"stdout","text":"Тип: <class 'torch.Tensor'>\nФорма тензора: torch.Size([3, 224, 224])\nМітка (індекс): 0\nНазва класу: Apple Braeburn\nЗразок [0]: форма torch.Size([3, 224, 224]), мітка: 0 → Apple Braeburn\nЗразок [492]: форма torch.Size([3, 224, 224]), мітка: 1 → Apple Granny Smith\nЗразок [984]: форма torch.Size([3, 224, 224]), мітка: 2 → Apricot\nЗразок [1476]: форма torch.Size([3, 224, 224]), мітка: 3 → Avocado\nЗразок [1903]: форма torch.Size([3, 224, 224]), мітка: 4 → Banana\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Розмір батчу\nbatch_size = 32\n\n# Створюємо DataLoader для тренувальних та тестових даних\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# Перевірка\nfor images, labels in train_loader:\n    print(f\"Форма батчу зображень: {images.shape}\")  # [batch_size, 3, 224, 224]\n    print(f\"Форма батчу міток: {labels.shape}\")       # [batch_size]\n    break  # Виводимо тільки перший батч","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-18T04:01:28.458646Z","iopub.execute_input":"2026-02-18T04:01:28.459057Z","iopub.status.idle":"2026-02-18T04:01:28.725083Z","shell.execute_reply.started":"2026-02-18T04:01:28.459027Z","shell.execute_reply":"2026-02-18T04:01:28.723909Z"}},"outputs":[{"name":"stdout","text":"Форма батчу зображень: torch.Size([32, 3, 224, 224])\nФорма батчу міток: torch.Size([32])\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Візуалізація кількох зразків з тренувального набору\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\nfor i, ax in enumerate(axes.flat):\n    img, label = train_dataset[i]\n    # Конвертуємо тензор [C, H, W] → [H, W, C] для matplotlib\n    img_np = img.permute(1, 2, 0).numpy()\n    ax.imshow(img_np)\n    ax.set_title(train_dataset.classes[label])\n    ax.axis('off')\n\nplt.suptitle(\"Зразки з тренувального датасету\", fontsize=16)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}